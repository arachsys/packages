diff --git a/Cargo.lock b/Cargo.lock
index d2f13bfd..fb2107b8 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -308,6 +308,7 @@ version = "0.1.0"
 dependencies = [
  "byteorder",
  "crc-any",
+ "epoll",
  "io-uring",
  "libc",
  "log",
diff --git a/block/Cargo.toml b/block/Cargo.toml
index db4ac9a6..63c71eb5 100644
--- a/block/Cargo.toml
+++ b/block/Cargo.toml
@@ -20,7 +20,7 @@ smallvec = "1.15.1"
 thiserror = { workspace = true }
 uuid = { workspace = true, features = ["v4"] }
 virtio-bindings = { workspace = true }
-virtio-queue = { workspace = true }
+virtio-queue = { workspace = true, features = ["test-utils"] }
 vm-memory = { workspace = true, features = [
   "backend-atomic",
   "backend-bitmap",
@@ -28,3 +28,6 @@ vm-memory = { workspace = true, features = [
 ] }
 vm-virtio = { path = "../vm-virtio" }
 vmm-sys-util = { workspace = true }
+
+[dev-dependencies]
+epoll = { workspace = true }
diff --git a/block/src/async_io.rs b/block/src/async_io.rs
index aa31c543..8ac0b58e 100644
--- a/block/src/async_io.rs
+++ b/block/src/async_io.rs
@@ -82,6 +82,12 @@ pub enum AsyncIoError {
     /// Failed submitting batch requests.
     #[error("Failed submitting batch requests: {0}")]
     SubmitBatchRequests(#[source] std::io::Error),
+    /// Failed to punch hole file.
+    #[error("Failed to punch hole file: {0}")]
+    PunchHole(#[source] std::io::Error),
+    /// Failed to write zeroes to file.
+    #[error("Failed to write zeroes to file: {0}")]
+    WriteZeroes(#[source] std::io::Error),
 }
 
 pub type AsyncIoResult<T> = std::result::Result<T, AsyncIoError>;
@@ -108,4 +114,50 @@ pub trait AsyncIo: Send {
     fn submit_batch_requests(&mut self, _batch_request: &[BatchRequest]) -> AsyncIoResult<()> {
         Ok(())
     }
+    /// Replace a range of bytes with a hole.
+    ///
+    /// # Arguments
+    ///
+    /// * `offset`: offset of the file where to replace with a hole.
+    /// * `length`: the number of bytes of the hole to replace with.
+    fn punch_hole(&mut self, _offset: u64, _length: u64, _user_data: u64) -> AsyncIoResult<()> {
+        Err(AsyncIoError::WriteZeroes(std::io::Error::other(
+            "PunchHole doesn't support yet",
+        )))
+    }
+    /// Write up to `length` bytes of zeroes starting at `offset`, returning how many bytes were
+    /// written.
+    ///
+    /// # Arguments
+    ///
+    /// * `offset`: offset of the file where to write zeroes.
+    /// * `length`: the number of bytes of zeroes to write to the stream.
+    fn write_zeroes_at(
+        &mut self,
+        _offset: u64,
+        _length: usize,
+        _user_data: Option<u64>,
+    ) -> std::io::Result<usize> {
+        Err(std::io::Error::other("WriteZeroesAt doesn't support yet"))
+    }
+
+    /// Write zeroes starting at `offset` until `length` bytes have been written.
+    ///
+    /// This method will continuously write zeroes until the requested `length` is satisfied or an
+    /// unrecoverable error is encountered.
+    ///
+    /// # Arguments
+    ///
+    /// * `offset`: offset of the file where to write zeroes.
+    /// * `length`: the exact number of bytes of zeroes to write to the stream.
+    fn write_all_zeroes_at(
+        &mut self,
+        _offset: u64,
+        _length: usize,
+        _user_data: u64,
+    ) -> AsyncIoResult<()> {
+        Err(AsyncIoError::WriteZeroes(std::io::Error::other(
+            "WriteAllZeroesAt doesn't support yet",
+        )))
+    }
 }
diff --git a/block/src/lib.rs b/block/src/lib.rs
index 5599258e..f30ae943 100644
--- a/block/src/lib.rs
+++ b/block/src/lib.rs
@@ -41,7 +41,7 @@ use std::os::unix::io::AsRawFd;
 use std::path::Path;
 use std::sync::Arc;
 use std::time::Instant;
-use std::{cmp, result};
+use std::{cmp, mem, result};
 
 #[cfg(feature = "io_uring")]
 use io_uring::{IoUring, Probe, opcode};
@@ -53,7 +53,7 @@ use virtio_bindings::virtio_blk::*;
 use virtio_queue::DescriptorChain;
 use vm_memory::bitmap::Bitmap;
 use vm_memory::{
-    ByteValued, Bytes, GuestAddress, GuestMemory, GuestMemoryError, GuestMemoryLoadGuard,
+    Address, ByteValued, Bytes, GuestAddress, GuestMemory, GuestMemoryError, GuestMemoryLoadGuard,
 };
 use vm_virtio::{AccessPlatform, Translatable};
 use vmm_sys_util::eventfd::EventFd;
@@ -95,6 +95,12 @@ pub enum Error {
     TooManyDescriptors,
     #[error("Failure in vhdx")]
     VhdxError(#[source] VhdxError),
+    #[error("Invalid file access")]
+    InvalidAccess,
+    #[error("Failed to punch hole: {0}")]
+    PunchHole(AsyncIoError),
+    #[error("Failed to write zeroes: {0}")]
+    WriteZeroes(AsyncIoError),
 }
 
 fn build_device_id(disk_path: &Path) -> result::Result<String, Error> {
@@ -161,6 +167,8 @@ pub enum ExecuteError {
     AsyncFlush(#[source] AsyncIoError),
     #[error("Failed allocating a temporary buffer")]
     TemporaryBufferAllocation(#[source] io::Error),
+    #[error("Failed to handle discard or write zeroes: {0}")]
+    DiscardWriteZeroes(Error),
 }
 
 impl ExecuteError {
@@ -181,6 +189,7 @@ impl ExecuteError {
             ExecuteError::AsyncWrite(_) => VIRTIO_BLK_S_IOERR,
             ExecuteError::AsyncFlush(_) => VIRTIO_BLK_S_IOERR,
             ExecuteError::TemporaryBufferAllocation(_) => VIRTIO_BLK_S_IOERR,
+            ExecuteError::DiscardWriteZeroes(_) => VIRTIO_BLK_S_IOERR,
         };
         status as u8
     }
@@ -192,6 +201,8 @@ pub enum RequestType {
     Out,
     Flush,
     GetDeviceId,
+    Discard,
+    WriteZeroes,
     Unsupported(u32),
 }
 
@@ -205,6 +216,8 @@ pub fn request_type<B: Bitmap + 'static>(
         VIRTIO_BLK_T_OUT => Ok(RequestType::Out),
         VIRTIO_BLK_T_FLUSH => Ok(RequestType::Flush),
         VIRTIO_BLK_T_GET_ID => Ok(RequestType::GetDeviceId),
+        VIRTIO_BLK_T_DISCARD => Ok(RequestType::Discard),
+        VIRTIO_BLK_T_WRITE_ZEROES => Ok(RequestType::WriteZeroes),
         t => Ok(RequestType::Unsupported(t)),
     }
 }
@@ -232,6 +245,24 @@ pub struct AlignedOperation {
     layout: Layout,
 }
 
+/// One or more `DiscardWriteZeroes` structs are used to describe the data for
+/// discard or write zeroes command.
+#[derive(Copy, Clone, Debug, Default)]
+#[repr(C)]
+struct DiscardWriteZeroes {
+    sector: u64,
+    num_sectors: u32,
+    flags: u32,
+}
+
+impl DiscardWriteZeroes {
+    // Size of DiscardWriteZeroes struct.
+    const LEN: u64 = mem::size_of::<DiscardWriteZeroes>() as u64;
+}
+
+// SAFETY: Safe because DiscardWriteZeroes contains only plain data.
+unsafe impl ByteValued for DiscardWriteZeroes {}
+
 pub struct BatchRequest {
     pub offset: libc::off_t,
     pub iovecs: SmallVec<[libc::iovec; DEFAULT_DESCRIPTOR_VEC_SIZE]>,
@@ -398,6 +429,12 @@ impl Request {
                     mem.write_slice(serial, *data_addr)
                         .map_err(ExecuteError::Write)?;
                 }
+                RequestType::Discard => {
+                    return Err(ExecuteError::Unsupported(VIRTIO_BLK_T_DISCARD));
+                }
+                RequestType::WriteZeroes => {
+                    return Err(ExecuteError::Unsupported(VIRTIO_BLK_T_WRITE_ZEROES));
+                }
                 RequestType::Unsupported(t) => return Err(ExecuteError::Unsupported(t)),
             };
         }
@@ -411,6 +448,7 @@ impl Request {
         disk_image: &mut dyn AsyncIo,
         serial: &[u8],
         user_data: u64,
+        write_zeroes_unmap: bool,
     ) -> result::Result<ExecuteAsync, ExecuteError> {
         let sector = self.sector;
         let request_type = self.request_type;
@@ -546,12 +584,115 @@ impl Request {
                 ret.async_complete = false;
                 return Ok(ret);
             }
+            RequestType::Discard | RequestType::WriteZeroes => {
+                for (data_addr, data_len) in &self.data_descriptors {
+                    let data_len = *data_len as u64;
+                    // We support for now only data descriptors with the `len` field = multiple of
+                    // the size of `virtio_blk_discard_write_zeroes` segment. The specification,
+                    // however, requires that only `total_len` be such multiple (a segment can be
+                    // divided between several descriptors). Once we switch to a more general
+                    // approach regarding how we store and parse the device buffers, we'll fix this
+                    // too.
+                    if !data_len.is_multiple_of(DiscardWriteZeroes::LEN) {
+                        return Err(ExecuteError::BadRequest(Error::InvalidOffset));
+                    }
+                    let mut available_bytes = data_len;
+                    let mut crt_addr = *data_addr;
+
+                    while available_bytes >= DiscardWriteZeroes::LEN {
+                        let segment: DiscardWriteZeroes = mem
+                            .read_obj(crt_addr)
+                            .map_err(|e| ExecuteError::BadRequest(Error::GuestMemory(e)))?;
+
+                        // For Discard, unmap bit (the least significant bit from segment flags)
+                        // MUST be 0, for Write Zeroes it can be either 0 or 1.
+                        // The other bits are reserved and MUST not be set (for both request types).
+                        // If any of these conditions are not met, status must be set to
+                        // VIRTIO_BLK_S_UNSUPP.
+                        // Verify two invalid request case:
+                        //1. Discard request: any unknown flag is set or unmap flag is set.
+                        //2. Write zeroes request: any unknown flag is set.
+                        if request_type == RequestType::Discard && segment.flags != 0 {
+                            return Err(ExecuteError::Unsupported(VIRTIO_BLK_T_DISCARD));
+                        } else if request_type == RequestType::WriteZeroes
+                            && segment.flags & !1 != 0
+                        {
+                            return Err(ExecuteError::Unsupported(VIRTIO_BLK_T_WRITE_ZEROES));
+                        }
+
+                        Self::handle_discard_write_zeroes_sync(
+                            &segment,
+                            request_type,
+                            disk_nsectors,
+                            write_zeroes_unmap,
+                            disk_image,
+                            user_data,
+                        )
+                        .map_err(ExecuteError::DiscardWriteZeroes)?;
+                        // Using `unchecked_add` here, since the overflow is not possible at this
+                        // point (it is checked when parsing the request) and `read_obj` fails if
+                        // the memory access is invalid.
+                        crt_addr = crt_addr.unchecked_add(DiscardWriteZeroes::LEN);
+                        available_bytes -= DiscardWriteZeroes::LEN;
+                    }
+                }
+            }
             RequestType::Unsupported(t) => return Err(ExecuteError::Unsupported(t)),
         }
 
         Ok(ret)
     }
 
+    fn handle_discard_write_zeroes_sync(
+        segment: &DiscardWriteZeroes,
+        request_type: RequestType,
+        disk_nsectors: u64,
+        write_zeroes_unmap: bool,
+        disk_image: &mut dyn AsyncIo,
+        user_data: u64,
+    ) -> Result<(), Error> {
+        let sector = segment.sector;
+        let num_sectors = segment.num_sectors;
+        let _flags = segment.flags;
+
+        let offset = sector
+            .checked_shl(u32::from(SECTOR_SHIFT))
+            .ok_or(Error::InvalidAccess)?;
+        let length = u64::from(num_sectors)
+            .checked_shl(u32::from(SECTOR_SHIFT))
+            .ok_or(Error::InvalidAccess)?;
+
+        let mut sectors_count = num_sectors as u64;
+        sectors_count = sectors_count
+            .checked_add(sector)
+            .ok_or(Error::InvalidAccess)?;
+        if sectors_count > disk_nsectors {
+            return Err(Error::InvalidAccess);
+        }
+
+        // Unmap has two different cases:
+        // - request type is Discard
+        // - request type is Write Zeroes and unmap bit is set
+        if request_type == RequestType::Discard {
+            // Since Discard is just a hint and some filesystems may not implement
+            // FALLOC_FL_PUNCH_HOLE, ignore punch_hole() errors.
+            disk_image
+                .punch_hole(offset, length, user_data)
+                .map_err(Error::PunchHole)?;
+        } else {
+            // If unmap is set, try at first to punch a hole, if it fails, fall back to just
+            // writing zeroes.
+            // After a write zeroes command is completed, reads of the specified ranges of sectors
+            // MUST return zeroes, independent of unmap value.
+            if !write_zeroes_unmap || disk_image.punch_hole(offset, length, user_data).is_err() {
+                disk_image
+                    .write_all_zeroes_at(offset, length as usize, user_data)
+                    .map_err(Error::WriteZeroes)?;
+            }
+        }
+        Ok(())
+    }
+
     pub fn complete_async(&mut self) -> result::Result<(), Error> {
         for aligned_operation in self.aligned_operations.drain(..) {
             // We need to perform the copy after the data has been read inside
@@ -859,9 +1000,10 @@ impl Default for DiskTopology {
 }
 
 ioctl_io_nr!(BLKSSZGET, 0x12, 104);
-ioctl_io_nr!(BLKPBSZGET, 0x12, 123);
+ioctl_io_nr!(BLKDISCARD, 0x12, 119);
 ioctl_io_nr!(BLKIOMIN, 0x12, 120);
 ioctl_io_nr!(BLKIOOPT, 0x12, 121);
+ioctl_io_nr!(BLKPBSZGET, 0x12, 123);
 
 enum BlockSize {
     LogicalBlock,
@@ -920,3 +1062,702 @@ impl DiskTopology {
         })
     }
 }
+
+#[cfg(test)]
+mod tests {
+    use std::os::fd::FromRawFd;
+    use std::sync::Arc;
+
+    use virtio_bindings::bindings::virtio_ring::VRING_DESC_F_WRITE;
+    use virtio_queue::desc::RawDescriptor;
+    use virtio_queue::desc::split::Descriptor;
+    use virtio_queue::mock::MockSplitQueue;
+    use virtio_queue::{Queue, QueueT};
+    use vm_memory::bitmap::AtomicBitmap;
+    use vm_memory::{GuestAddressSpace, GuestMemoryAtomic, GuestMemoryMmap};
+    use vmm_sys_util::tempfile::TempFile;
+
+    use super::*;
+    use crate::async_io::DiskFile;
+    #[cfg(feature = "io_uring")]
+    use crate::raw_async::RawFileDisk;
+    use crate::raw_sync::RawFileDiskSync;
+
+    const COMPLETION_EVENT: u16 = 17;
+
+    #[derive(Copy, Clone, Debug, Default)]
+    #[repr(C)]
+    struct RequestHeader {
+        request_type: u32,
+        _reserved: u32,
+        sector: u64,
+    }
+
+    // SAFETY: data structure only contain a series of integers
+    unsafe impl ByteValued for RequestHeader {}
+
+    fn read_data_vec(
+        disk_image_async: &mut dyn AsyncIo,
+        user_data: u64,
+        offset: u64,
+        len: usize,
+    ) -> Vec<u8> {
+        let mut data_vec = vec![0u8; len];
+        let iovec = vec![libc::iovec {
+            iov_base: data_vec.as_mut_ptr() as *mut libc::c_void,
+            iov_len: len as libc::size_t,
+        }];
+        disk_image_async
+            .read_vectored(offset as libc::off_t, &iovec, user_data)
+            .unwrap();
+        data_vec
+    }
+
+    #[test]
+    fn test_parse_request() {
+        let mem: GuestMemoryMmap<AtomicBitmap> =
+            GuestMemoryMmap::from_ranges(&[(GuestAddress(0), 0x1000_0000)]).unwrap();
+        let vq = MockSplitQueue::new(&mem, 128);
+
+        {
+            let v = [
+                // A device-writable request header descriptor.
+                RawDescriptor::from(Descriptor::new(
+                    0x10_0000,
+                    0x100,
+                    VRING_DESC_F_WRITE as u16,
+                    0,
+                )),
+                RawDescriptor::from(Descriptor::new(
+                    0x20_0000,
+                    0x100,
+                    VRING_DESC_F_WRITE as u16,
+                    0,
+                )),
+                RawDescriptor::from(Descriptor::new(
+                    0x30_0000,
+                    0x100,
+                    VRING_DESC_F_WRITE as u16,
+                    0,
+                )),
+            ];
+            vq.build_desc_chain(&v).unwrap();
+            let mut queue: Queue = vq.create_queue().unwrap();
+            let req_header = RequestHeader {
+                request_type: VIRTIO_BLK_T_IN,
+                _reserved: 0,
+                sector: 2,
+            };
+            mem.write_obj::<RequestHeader>(req_header, GuestAddress(0x10_0000))
+                .unwrap();
+            let mem_atomic: GuestMemoryAtomic<GuestMemoryMmap<AtomicBitmap>> =
+                GuestMemoryAtomic::from(Arc::new(mem.clone()));
+            let mut chain = queue.pop_descriptor_chain(mem_atomic.memory()).unwrap();
+            // Request header descriptor should be device-readable.
+            Request::parse(&mut chain, None).unwrap_err();
+        }
+
+        // Valid descriptor chain for FLUSH.
+        {
+            let v = [
+                RawDescriptor::from(Descriptor::new(0x10_0000, 0x100, 0, 0)),
+                RawDescriptor::from(Descriptor::new(
+                    0x40_0000,
+                    0x100,
+                    VRING_DESC_F_WRITE as u16,
+                    0,
+                )),
+            ];
+            vq.build_desc_chain(&v).unwrap();
+            let mut queue: Queue = vq.create_queue().unwrap();
+            let req_header = RequestHeader {
+                request_type: VIRTIO_BLK_T_FLUSH,
+                _reserved: 0,
+                sector: 0,
+            };
+            mem.write_obj::<RequestHeader>(req_header, GuestAddress(0x10_0000))
+                .unwrap();
+
+            let mem_atomic: GuestMemoryAtomic<GuestMemoryMmap<AtomicBitmap>> =
+                GuestMemoryAtomic::from(Arc::new(mem));
+            let mut chain = queue.pop_descriptor_chain(mem_atomic.memory()).unwrap();
+            Request::parse(&mut chain, None).unwrap();
+        }
+    }
+
+    #[cfg(feature = "io_uring")]
+    #[test]
+    fn test_raw_io_uring_discard_wr_zeroes_request() {
+        _test_discard_wr_zeroes_request(true);
+    }
+
+    #[test]
+    fn test_raw_sync_discard_wr_zeroes_request() {
+        _test_discard_wr_zeroes_request(false);
+    }
+
+    fn _test_discard_wr_zeroes_request(raw_async_flag: bool) {
+        const NON_ZERO_VALUE: u8 = 0x55;
+
+        let f = TempFile::new().unwrap().into_file();
+        let disk_size = 0x1000u64;
+        let disk_nsectors = disk_size / SECTOR_SIZE; // 8
+        // 0x000-0x200: 0
+        // 0x200-0x400: 1
+        // 0x400-0x600: 2
+        // 0x600-0x800: 3
+        // 0x800-0xA00: 4
+        // 0xA00-0xC00: 5
+        // 0xC00-0xE00: 6
+        // 0xE00-0x1000: 7
+        f.set_len(disk_size).unwrap();
+        let mut disk_image = if raw_async_flag {
+            #[cfg(not(feature = "io_uring"))]
+            unreachable!("Checked in if statement above");
+            #[cfg(feature = "io_uring")]
+            {
+                Box::new(RawFileDisk::new(f)) as Box<dyn DiskFile>
+            }
+        } else {
+            Box::new(RawFileDiskSync::new(f)) as Box<dyn DiskFile>
+        };
+        let mut disk_image_async = disk_image.new_async_io(128).unwrap();
+        let disk_image_id_str = String::from("test image");
+        let disk_image_id = disk_image_id_str.as_bytes();
+
+        // Create the epoll file descriptor
+        let epoll_fd = epoll::create(true).unwrap();
+        // Use 'File' to enforce closing on 'epoll_fd'
+        // SAFETY: epoll_fd is a valid fd
+        let epoll_file = unsafe { File::from_raw_fd(epoll_fd) };
+        epoll::ctl(
+            epoll_file.as_raw_fd(),
+            epoll::ControlOptions::EPOLL_CTL_ADD,
+            disk_image_async.notifier().as_raw_fd(),
+            epoll::Event::new(epoll::Events::EPOLLIN, COMPLETION_EVENT.into()),
+        )
+        .unwrap();
+        let mut events = [epoll::Event::new(epoll::Events::empty(), 0); 1];
+        let timeout = -1;
+
+        let mem: GuestMemoryMmap<AtomicBitmap> =
+            GuestMemoryMmap::from_ranges(&[(GuestAddress(0), 0x1000_0000)]).unwrap();
+        let vq = MockSplitQueue::new(&mem, 128);
+        let v = [
+            RawDescriptor::from(Descriptor::new(0x10_0000, 0x100, 0, 0)),
+            // 0x100:0 0x200: NON_ZERO_VALUE 0x100: 0
+            RawDescriptor::from(Descriptor::new(0x100, 0x400, 0, 0)),
+            // 0x80: NON_ZERO_VALUE 0x120: 0
+            RawDescriptor::from(Descriptor::new(0x800, 0x200, 0, 0)),
+            RawDescriptor::from(Descriptor::new(
+                0x40_0000,
+                0x100,
+                VRING_DESC_F_WRITE as u16,
+                0,
+            )),
+        ];
+        vq.build_desc_chain(&v).unwrap();
+        let mut queue: Queue = vq.create_queue().unwrap();
+
+        mem.write_slice(&[NON_ZERO_VALUE; 0x200], GuestAddress(0x200))
+            .unwrap();
+        mem.write_slice(&[NON_ZERO_VALUE; 0x100], GuestAddress(0x880))
+            .unwrap();
+        let req_header = RequestHeader {
+            request_type: VIRTIO_BLK_T_OUT,
+            _reserved: 0,
+            sector: 1,
+        };
+        mem.write_obj::<RequestHeader>(req_header, GuestAddress(0x10_0000))
+            .unwrap();
+
+        {
+            let mem_atomic: GuestMemoryAtomic<GuestMemoryMmap<AtomicBitmap>> =
+                GuestMemoryAtomic::from(Arc::new(mem.clone()));
+            let mut chain = queue.pop_descriptor_chain(mem_atomic.memory()).unwrap();
+            let mut request = Request::parse(&mut chain, None).unwrap();
+
+            // We will write in file at sector 1 (offset 0x200) 0x400 bytes from 0x100 guest memory
+            // address and 0x200 bytes from 0x800 address. 0 bytes should've been written in memory.
+            request
+                .execute_async(
+                    chain.memory(),
+                    disk_nsectors,
+                    disk_image_async.as_mut(),
+                    disk_image_id,
+                    chain.head_index() as u64,
+                    false,
+                )
+                .unwrap();
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            // file data now:
+            // 0x000-0x300: 0
+            // 0x300-0x500: NON_ZERO_VALUE
+            // 0x500-0x680: 0
+            // 0x680-0x780: NON_ZERO_VALUE
+            // 0x780-0x800: 0
+        }
+
+        // Let's write some more bytes to the file.
+        mem.write_slice(&[NON_ZERO_VALUE + 1; 0x600], GuestAddress(0x3100))
+            .unwrap();
+
+        // Write at offset 0x600 in file, 800 bytes: the first 100 bytes = 0, the next 600 bytes =
+        // = NON_ZERO_VALUE + 1 and the last 100 bytes = 0; and then at offset 0x600 + 0x800 =
+        // = 0xE00, which is the last sector, 200 bytes = NON_ZERO_VALUE.
+        let v = [
+            RawDescriptor::from(Descriptor::new(0x10_0000, 0x100, 0, 0)),
+            // 0x100:0 0x600: NON_ZERO_VALUE+1 0x100: 0
+            RawDescriptor::from(Descriptor::new(0x3000, 0x800, 0, 0)),
+            // 0x200: NON_ZERO_VALUE
+            RawDescriptor::from(Descriptor::new(0x200, 0x200, 0, 0)),
+            RawDescriptor::from(Descriptor::new(
+                0x40_0000,
+                0x100,
+                VRING_DESC_F_WRITE as u16,
+                0,
+            )),
+        ];
+        vq.build_desc_chain(&v).unwrap();
+        let mut queue: Queue = vq.create_queue().unwrap();
+
+        let req_header = RequestHeader {
+            request_type: VIRTIO_BLK_T_OUT,
+            _reserved: 0,
+            sector: 3,
+        };
+        mem.write_obj::<RequestHeader>(req_header, GuestAddress(0x10_0000))
+            .unwrap();
+
+        {
+            let mem_atomic: GuestMemoryAtomic<GuestMemoryMmap<AtomicBitmap>> =
+                GuestMemoryAtomic::from(Arc::new(mem.clone()));
+            let mut chain = queue.pop_descriptor_chain(mem_atomic.memory()).unwrap();
+            let mut request = Request::parse(&mut chain, None).unwrap();
+
+            // We will write in file at sector 1 (offset 0x200) 0x400 bytes from 0x100 guest memory
+            // address and 0x200 bytes from 0x800 address. 0 bytes should've been written in memory.
+            request
+                .execute_async(
+                    chain.memory(),
+                    disk_nsectors,
+                    disk_image_async.as_mut(),
+                    disk_image_id,
+                    chain.head_index() as u64,
+                    false,
+                )
+                .unwrap();
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            // file data now:
+            // 0x000-0x300: 0
+            // 0x300-0x500: NON_ZERO_VALUE
+            // 0x500-0x700: 0
+            // 0x700-0xD00: NON_ZERO_VALUE + 1
+            // 0xD00-0xE00: 0
+            // 0xE00-0x1000: NON_ZERO_VALUE
+        }
+
+        // Test write zeroes request.
+        // Write zeroes at offset 0x400 in file, 2 sectors = 0x400 bytes.
+        let wr_zeroes_1 = DiscardWriteZeroes {
+            sector: 2,
+            num_sectors: 2,
+            flags: 0,
+        };
+        mem.write_obj::<DiscardWriteZeroes>(wr_zeroes_1, GuestAddress(0x1000))
+            .unwrap();
+        // Write zeroes at offset 0xA00 in file, 1 sector = 0x200 bytes.
+        let wr_zeroes_2 = DiscardWriteZeroes {
+            sector: 5,
+            num_sectors: 1,
+            flags: 0,
+        };
+        mem.write_obj::<DiscardWriteZeroes>(wr_zeroes_2, GuestAddress(0x4000))
+            .unwrap();
+
+        let v = [
+            RawDescriptor::from(Descriptor::new(0x10_0000, 0x100, 0, 0)),
+            RawDescriptor::from(Descriptor::new(
+                0x1000,
+                DiscardWriteZeroes::LEN as u32,
+                0,
+                0,
+            )),
+            RawDescriptor::from(Descriptor::new(
+                0x4000,
+                DiscardWriteZeroes::LEN as u32,
+                0,
+                0,
+            )),
+            RawDescriptor::from(Descriptor::new(
+                0x40_0000,
+                0x100,
+                VRING_DESC_F_WRITE as u16,
+                0,
+            )),
+        ];
+        vq.build_desc_chain(&v).unwrap();
+        let mut queue: Queue = vq.create_queue().unwrap();
+
+        let req_header = RequestHeader {
+            request_type: VIRTIO_BLK_T_WRITE_ZEROES,
+            _reserved: 0,
+            sector: 2,
+        };
+        mem.write_obj::<RequestHeader>(req_header, GuestAddress(0x10_0000))
+            .unwrap();
+
+        {
+            let mem_atomic: GuestMemoryAtomic<GuestMemoryMmap<AtomicBitmap>> =
+                GuestMemoryAtomic::from(Arc::new(mem.clone()));
+            let mut chain = queue.pop_descriptor_chain(mem_atomic.memory()).unwrap();
+            let mut request = Request::parse(&mut chain, None).unwrap();
+
+            // 0 bytes should've been written in memory.
+            request
+                .execute_async(
+                    chain.memory(),
+                    disk_nsectors,
+                    disk_image_async.as_mut(),
+                    disk_image_id,
+                    chain.head_index() as u64,
+                    false,
+                )
+                .unwrap();
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+
+            // expected file data:
+            // 0x000-0x300: 0
+            // 0x300-0x400: NON_ZERO_VALUE
+            // 0x400-0x800: 0
+            // 0x800-0xA00: NON_ZERO_VALUE + 1
+            // 0xA00-0xC00: 0
+            // 0xC00-0xD00: NON_ZERO_VALUE + 1
+            // 0xD00-0xE00: 0
+            // 0xE00-0x1000: NON_ZERO_VALUE
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0x0,
+                0x300,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![0x0; 0x300]);
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0x300,
+                0x100,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![NON_ZERO_VALUE; 0x100]);
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0x400,
+                0x400,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![0x0; 0x400]);
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0x800,
+                0x200,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![NON_ZERO_VALUE + 1; 0x200]);
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0xA00,
+                0x200,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![0; 0x200]);
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0xC00,
+                0x100,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![NON_ZERO_VALUE + 1; 0x100]);
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0xD00,
+                0x100,
+            );
+            assert_eq!(data_vec, vec![0; 0x100]);
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0xE00,
+                0x100,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![NON_ZERO_VALUE; 0x100]);
+        }
+
+        // Test discard request.
+        let discard_req = DiscardWriteZeroes {
+            sector: 7,
+            num_sectors: 1,
+            flags: 0,
+        };
+        mem.write_obj::<DiscardWriteZeroes>(discard_req, GuestAddress(0x1000))
+            .unwrap();
+
+        let v = [
+            RawDescriptor::from(Descriptor::new(0x10_0000, 0x100, 0, 0)),
+            RawDescriptor::from(Descriptor::new(
+                0x1000,
+                DiscardWriteZeroes::LEN as u32,
+                0,
+                0,
+            )),
+            RawDescriptor::from(Descriptor::new(
+                0x40_0000,
+                0x100,
+                VRING_DESC_F_WRITE as u16,
+                0,
+            )),
+        ];
+        vq.build_desc_chain(&v).unwrap();
+        let mut queue: Queue = vq.create_queue().unwrap();
+
+        let req_header = RequestHeader {
+            request_type: VIRTIO_BLK_T_DISCARD,
+            _reserved: 0,
+            sector: 7,
+        };
+        mem.write_obj::<RequestHeader>(req_header, GuestAddress(0x10_0000))
+            .unwrap();
+
+        {
+            let mem_atomic: GuestMemoryAtomic<GuestMemoryMmap<AtomicBitmap>> =
+                GuestMemoryAtomic::from(Arc::new(mem.clone()));
+            let mut chain = queue.pop_descriptor_chain(mem_atomic.memory()).unwrap();
+            let mut request = Request::parse(&mut chain, None).unwrap();
+
+            request
+                .execute_async(
+                    chain.memory(),
+                    disk_nsectors,
+                    disk_image_async.as_mut(),
+                    disk_image_id,
+                    chain.head_index() as u64,
+                    false,
+                )
+                .unwrap();
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0xE00,
+                0x200,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            assert_eq!(evt_num, 1);
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data_vec, vec![0x0; 0x200]);
+            // Even though we punched a hole at the end of the file, the file size should remain the
+            // same since FALLOC_FL_PUNCH_HOLE is used with FALLOC_FL_KEEP_SIZE.
+            assert_eq!(disk_image.size().unwrap(), 0x1000);
+        }
+
+        // Test that write zeroes request with unmap bit set is okay.
+        let wr_zeroes_req = DiscardWriteZeroes {
+            sector: 4,
+            num_sectors: 1,
+            flags: 0x0001,
+        };
+        mem.write_obj::<DiscardWriteZeroes>(wr_zeroes_req, GuestAddress(0x1000))
+            .unwrap();
+
+        let v = [
+            RawDescriptor::from(Descriptor::new(0x10_0000, 0x100, 0, 0)),
+            RawDescriptor::from(Descriptor::new(
+                0x1000,
+                DiscardWriteZeroes::LEN as u32,
+                0,
+                0,
+            )),
+            RawDescriptor::from(Descriptor::new(
+                0x40_0000,
+                0x100,
+                VRING_DESC_F_WRITE as u16,
+                0,
+            )),
+        ];
+        vq.build_desc_chain(&v).unwrap();
+        let mut queue: Queue = vq.create_queue().unwrap();
+
+        let req_header = RequestHeader {
+            request_type: VIRTIO_BLK_T_WRITE_ZEROES,
+            _reserved: 0,
+            sector: 7,
+        };
+        mem.write_obj::<RequestHeader>(req_header, GuestAddress(0x10_0000))
+            .unwrap();
+
+        {
+            let mem_atomic: GuestMemoryAtomic<GuestMemoryMmap<AtomicBitmap>> =
+                GuestMemoryAtomic::from(Arc::new(mem.clone()));
+            let mut chain = queue.pop_descriptor_chain(mem_atomic.memory()).unwrap();
+            let mut request = Request::parse(&mut chain, None).unwrap();
+
+            let data_vec = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0x800,
+                0x200,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            // Data is != 0 before the write zeroes request.
+            assert_eq!(data_vec, vec![NON_ZERO_VALUE + 1; 0x200]);
+
+            // Let's write some data in the file right before and after the fourth sector to confirm
+            // that those regions won't be zeroed out.
+            // After the fourth sector:
+            let mut v = vec![NON_ZERO_VALUE + 2; 0x200];
+            disk_image_async
+                .write_vectored(
+                    0xA00 as libc::off_t,
+                    &[libc::iovec {
+                        iov_base: v.as_mut_ptr() as *mut libc::c_void,
+                        iov_len: v.len() as libc::size_t,
+                    }],
+                    chain.head_index() as u64,
+                )
+                .unwrap();
+            // Before the fourth sector:
+            disk_image_async
+                .write_vectored(
+                    0x600 as libc::off_t,
+                    &[libc::iovec {
+                        iov_base: v.as_mut_ptr() as *mut libc::c_void,
+                        iov_len: v.len() as libc::size_t,
+                    }],
+                    chain.head_index() as u64,
+                )
+                .unwrap();
+
+            // 0 bytes should've been written in memory.
+            request
+                .execute_async(
+                    chain.memory(),
+                    disk_nsectors,
+                    disk_image_async.as_mut(),
+                    disk_image_id,
+                    chain.head_index() as u64,
+                    false,
+                )
+                .unwrap();
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+
+            let data = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0x600,
+                0x200,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data, vec![NON_ZERO_VALUE + 2; 0x200]);
+
+            let data = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0x800,
+                0x200,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data, vec![0; 0x200]);
+
+            let data = read_data_vec(
+                disk_image_async.as_mut(),
+                chain.head_index() as u64,
+                0xA00,
+                0x200,
+            );
+            let evt_num = epoll::wait(epoll_file.as_raw_fd(), timeout, &mut events[..]).unwrap();
+            for event in events.iter().take(evt_num) {
+                assert_eq!(event.data as u16, COMPLETION_EVENT);
+                disk_image_async.notifier().read().unwrap();
+            }
+            assert_eq!(data, vec![NON_ZERO_VALUE + 2; 0x200]);
+        }
+    }
+}
diff --git a/block/src/raw_async.rs b/block/src/raw_async.rs
index 1a582073..101eb3b4 100644
--- a/block/src/raw_async.rs
+++ b/block/src/raw_async.rs
@@ -3,7 +3,7 @@
 // SPDX-License-Identifier: Apache-2.0 AND BSD-3-Clause
 
 use std::fs::File;
-use std::io::{Error, Seek, SeekFrom};
+use std::io::{Error, ErrorKind, Seek, SeekFrom};
 use std::os::unix::io::{AsRawFd, RawFd};
 
 use io_uring::{IoUring, opcode, types};
@@ -14,6 +14,8 @@ use crate::async_io::{
 };
 use crate::{BatchRequest, DiskTopology, RequestType};
 
+const ZERO_BUFFER_SIZE: usize = 64 * 1024;
+
 pub struct RawFileDisk {
     file: File,
 }
@@ -241,4 +243,86 @@ impl AsyncIo for RawFileAsync {
 
         Ok(())
     }
+
+    fn punch_hole(&mut self, offset: u64, length: u64, user_data: u64) -> AsyncIoResult<()> {
+        let (submitter, mut sq, _) = self.io_uring.split();
+
+        // SAFETY: we know the file descriptor is valid.
+        unsafe {
+            sq.push(
+                &opcode::Fallocate::new(types::Fd(self.fd), length)
+                    .offset(offset)
+                    .mode(libc::FALLOC_FL_PUNCH_HOLE | libc::FALLOC_FL_KEEP_SIZE)
+                    .build()
+                    .user_data(user_data),
+            )
+            .map_err(|_| AsyncIoError::PunchHole(Error::other("Submission queue is full")))?
+        };
+
+        // Update the submission queue and submit new operations to the
+        // io_uring instance.
+        sq.sync();
+        submitter.submit().map_err(AsyncIoError::PunchHole)?;
+
+        Ok(())
+    }
+
+    fn write_zeroes_at(
+        &mut self,
+        offset: u64,
+        len: usize,
+        user_data: Option<u64>,
+    ) -> std::io::Result<usize> {
+        if let Some(user_data) = user_data {
+            self.write_all_zeroes_at(offset, len, user_data)
+                .map_err(|e| {
+                    std::io::Error::other(format!("failed to write whole buffer to file: {e}"))
+                })?;
+            return Ok(len);
+        }
+        Err(std::io::Error::new(
+            ErrorKind::InvalidData,
+            "failed to write zeroes since user_data is none",
+        ))
+    }
+
+    fn write_all_zeroes_at(
+        &mut self,
+        offset: u64,
+        len: usize,
+        user_data: u64,
+    ) -> AsyncIoResult<()> {
+        let (submitter, mut sq, _) = self.io_uring.split();
+
+        let zero_buffer = [0u8; ZERO_BUFFER_SIZE];
+        let mut total_written = 0;
+
+        let mut iovecs = Vec::with_capacity(1);
+        while total_written < len {
+            let bytes_to_write = std::cmp::min(len - total_written, ZERO_BUFFER_SIZE);
+            iovecs.push(libc::iovec {
+                // SAFETY: a pointer to our stack buffer
+                iov_base: zero_buffer.as_ptr() as *mut libc::c_void,
+                iov_len: bytes_to_write,
+            });
+            total_written += bytes_to_write;
+        }
+
+        // SAFETY: we know the file descriptor is valid.
+        unsafe {
+            sq.push(
+                &opcode::Writev::new(types::Fd(self.fd), iovecs.as_ptr(), iovecs.len() as u32)
+                    .offset(offset)
+                    .build()
+                    .user_data(user_data),
+            )
+            .map_err(|_| AsyncIoError::WriteVectored(Error::other("Submission queue is full")))?
+        };
+
+        // Update the submission queue and submit new operations to the
+        // io_uring instance.
+        sq.sync();
+        submitter.submit().map_err(AsyncIoError::WriteVectored)?;
+        Ok(())
+    }
 }
diff --git a/block/src/raw_sync.rs b/block/src/raw_sync.rs
index 6b98147e..074bbff2 100644
--- a/block/src/raw_sync.rs
+++ b/block/src/raw_sync.rs
@@ -4,15 +4,30 @@
 
 use std::collections::VecDeque;
 use std::fs::File;
-use std::io::{Seek, SeekFrom};
+use std::io::{Error, ErrorKind, Seek, SeekFrom};
+use std::mem::zeroed;
 use std::os::unix::io::{AsRawFd, RawFd};
 
+use libc::{S_IFBLK, S_IFMT, fstat, ioctl, stat};
 use vmm_sys_util::eventfd::EventFd;
 
-use crate::DiskTopology;
 use crate::async_io::{
     AsyncIo, AsyncIoError, AsyncIoResult, BorrowedDiskFd, DiskFile, DiskFileError, DiskFileResult,
 };
+use crate::{BLKDISCARD, DiskTopology};
+
+const ZERO_BUFFER_SIZE: usize = 64 * 1024;
+
+fn is_block_device(fd: RawFd) -> bool {
+    // SAFETY: FFI call
+    let mut st: stat = unsafe { zeroed() };
+    // SAFETY: fstat is a system call that takes a fd and a pointer to a stat structure.
+    let result = unsafe { fstat(fd, &mut st) };
+    if result != 0 {
+        return false;
+    }
+    (st.st_mode & S_IFMT) == S_IFBLK
+}
 
 pub struct RawFileDiskSync {
     file: File,
@@ -138,4 +153,121 @@ impl AsyncIo for RawFileSync {
     fn next_completed_request(&mut self) -> Option<(u64, i32)> {
         self.completion_list.pop_front()
     }
+
+    fn punch_hole(&mut self, offset: u64, len: u64, user_data: u64) -> AsyncIoResult<()> {
+        let result = if is_block_device(self.fd) {
+            let range: [u64; 2] = [offset, len];
+            // SAFETY: FFI call with valid arguments
+            unsafe {
+                ioctl(
+                    self.fd as libc::c_int,
+                    BLKDISCARD() as _,
+                    &range as *const u64,
+                )
+            }
+        } else {
+            // SAFETY: FFI call with valid arguments
+            unsafe {
+                libc::fallocate(
+                    self.fd,
+                    libc::FALLOC_FL_PUNCH_HOLE | libc::FALLOC_FL_KEEP_SIZE,
+                    offset as libc::off_t,
+                    len as libc::off_t,
+                )
+            }
+        };
+        if result != 0 {
+            return Err(AsyncIoError::PunchHole(std::io::Error::last_os_error()));
+        }
+
+        self.completion_list.push_back((user_data, result as i32));
+        self.eventfd.write(1).unwrap();
+        Ok(())
+    }
+
+    fn write_zeroes_at(
+        &mut self,
+        offset: u64,
+        len: usize,
+        user_data: Option<u64>,
+    ) -> std::io::Result<usize> {
+        let zero_buffer = [0u8; ZERO_BUFFER_SIZE];
+        let mut total_written = 0;
+        let mut current_offset = offset;
+
+        while total_written < len {
+            let bytes_to_write = std::cmp::min(len - total_written, ZERO_BUFFER_SIZE);
+            let iovs = [libc::iovec {
+                // SAFETY: a pointer to our stack buffer
+                iov_base: zero_buffer.as_ptr() as *mut libc::c_void,
+                iov_len: bytes_to_write,
+            }];
+
+            let bytes_written = loop {
+                // SAFETY: FFI call with valid arguments. We provide a valid file descriptor,
+                // a pointer to our iovs array, the count of iovs (1), and the offset.
+                let result = unsafe {
+                    libc::pwritev(
+                        self.fd,
+                        iovs.as_ptr(),
+                        iovs.len() as libc::c_int,
+                        current_offset as libc::off_t,
+                    )
+                };
+                if result < 0 {
+                    let err = std::io::Error::last_os_error();
+                    if err.kind() == ErrorKind::Interrupted {
+                        continue;
+                    }
+                    return Err(err);
+                }
+                break result as usize;
+            };
+            if bytes_written == 0 {
+                return Err(std::io::Error::new(
+                    ErrorKind::WriteZero,
+                    "failed to write whole buffer to file",
+                ));
+            }
+            total_written += bytes_written;
+            current_offset += bytes_written as u64;
+        }
+        if let Some(user_data) = user_data {
+            self.completion_list
+                .push_back((user_data, total_written as i32));
+            self.eventfd.write(1)?;
+        }
+        Ok(total_written)
+    }
+
+    fn write_all_zeroes_at(
+        &mut self,
+        mut offset: u64,
+        mut length: usize,
+        user_data: u64,
+    ) -> AsyncIoResult<()> {
+        let total = length;
+        while length > 0 {
+            match self.write_zeroes_at(offset, length, None) {
+                Ok(0) => return Err(AsyncIoError::WriteZeroes(Error::from(ErrorKind::WriteZero))),
+                Ok(bytes_written) => {
+                    length = length
+                        .checked_sub(bytes_written)
+                        .ok_or_else(|| AsyncIoError::WriteZeroes(Error::from(ErrorKind::Other)))?;
+                    offset = offset
+                        .checked_add(bytes_written as u64)
+                        .ok_or_else(|| AsyncIoError::WriteZeroes(Error::from(ErrorKind::Other)))?;
+                }
+                Err(e) => {
+                    // If the operation was interrupted, we should retry it.
+                    if e.kind() != ErrorKind::Interrupted {
+                        return Err(AsyncIoError::WriteZeroes(e));
+                    }
+                }
+            }
+        }
+        self.completion_list.push_back((user_data, total as i32));
+        self.eventfd.write(1).unwrap();
+        Ok(())
+    }
 }
diff --git a/fuzz/fuzz_targets/block.rs b/fuzz/fuzz_targets/block.rs
index c06f0dea..b842815d 100644
--- a/fuzz/fuzz_targets/block.rs
+++ b/fuzz/fuzz_targets/block.rs
@@ -59,6 +59,9 @@ fuzz_target!(|bytes: &[u8]| -> Corpus {
         PathBuf::from(""),
         false,
         false,
+        false,
+        false,
+        false,
         2,
         256,
         None,
diff --git a/scripts/dev_cli.sh b/scripts/dev_cli.sh
index 519517dc..8ffb9d0c 100755
--- a/scripts/dev_cli.sh
+++ b/scripts/dev_cli.sh
@@ -409,6 +409,7 @@ cmd_tests() {
         $DOCKER_RUNTIME run \
             --workdir "$CTR_CLH_ROOT_DIR" \
             --rm \
+            --security-opt seccomp=unconfined \
             --device $exported_device \
             --device /dev/net/tun \
             --cap-add net_admin \
diff --git a/virtio-devices/src/block.rs b/virtio-devices/src/block.rs
index dad4fd21..0b0b98a6 100644
--- a/virtio-devices/src/block.rs
+++ b/virtio-devices/src/block.rs
@@ -148,6 +148,7 @@ struct BlockEpollHandler {
     access_platform: Option<Arc<dyn AccessPlatform>>,
     host_cpus: Option<Vec<usize>>,
     acked_features: u64,
+    write_zeroes_unmap: bool,
 }
 
 fn has_feature(features: u64, feature_flag: u64) -> bool {
@@ -162,7 +163,21 @@ impl BlockEpollHandler {
             // if the VIRTIO_BLK_F_RO feature if offered, and MUST NOT write any data."
             return Err(ExecuteError::ReadOnly);
         }
-        Ok(())
+
+        match request_type {
+            RequestType::Flush if !has_feature(features, VIRTIO_BLK_F_FLUSH.into()) => {
+                Err(ExecuteError::Unsupported(VIRTIO_BLK_T_FLUSH))
+            }
+            RequestType::Discard if !has_feature(features, VIRTIO_BLK_F_DISCARD.into()) => {
+                Err(ExecuteError::Unsupported(VIRTIO_BLK_T_DISCARD))
+            }
+            RequestType::WriteZeroes
+                if !has_feature(features, VIRTIO_BLK_F_WRITE_ZEROES.into()) =>
+            {
+                Err(ExecuteError::Unsupported(VIRTIO_BLK_T_WRITE_ZEROES))
+            }
+            _ => Ok(()),
+        }
     }
 
     fn process_queue_submit(&mut self) -> Result<()> {
@@ -173,6 +188,7 @@ impl BlockEpollHandler {
         while let Some(mut desc_chain) = queue.pop_descriptor_chain(self.mem.memory()) {
             let mut request = Request::parse(&mut desc_chain, self.access_platform.as_ref())
                 .map_err(Error::RequestParsing)?;
+            debug!("virtio-blk request type: {:?}", request.request_type);
 
             // For virtio spec compliance
             // "A device MUST set the status byte to VIRTIO_BLK_S_IOERR for a write request
@@ -181,7 +197,7 @@ impl BlockEpollHandler {
                 warn!("Request check failed: {:x?} {:?}", request, e);
                 desc_chain
                     .memory()
-                    .write_obj(VIRTIO_BLK_S_IOERR, request.status_addr)
+                    .write_obj(e.status(), request.status_addr)
                     .map_err(Error::RequestStatus)?;
 
                 // If no asynchronous operation has been submitted, we can
@@ -234,6 +250,7 @@ impl BlockEpollHandler {
                 self.disk_image.as_mut(),
                 &self.serial,
                 desc_chain.head_index() as u64,
+                self.write_zeroes_unmap,
             );
 
             if let Ok(ExecuteAsync {
@@ -255,10 +272,10 @@ impl BlockEpollHandler {
                 batch_inflight_requests.push((desc_chain.head_index(), request));
             } else {
                 let status = match result {
-                    Ok(_) => VIRTIO_BLK_S_OK,
+                    Ok(_) => VIRTIO_BLK_S_OK as u8,
                     Err(e) => {
                         warn!("Request failed: {:x?} {:?}", request, e);
-                        VIRTIO_BLK_S_IOERR
+                        e.status()
                     }
                 };
 
@@ -640,6 +657,7 @@ pub struct Block {
     exit_evt: EventFd,
     serial: Vec<u8>,
     queue_affinity: BTreeMap<u16, Vec<usize>>,
+    write_zeroes_unmap: bool,
 }
 
 #[derive(Serialize, Deserialize)]
@@ -660,6 +678,9 @@ impl Block {
         disk_path: PathBuf,
         read_only: bool,
         iommu: bool,
+        discard: bool,
+        write_zeroes: bool,
+        write_zeroes_unmap: bool,
         num_queues: usize,
         queue_size: u16,
         serial: Option<String>,
@@ -707,6 +728,13 @@ impl Block {
                     avail_features |= 1u64 << VIRTIO_BLK_F_RO;
                 }
 
+                if discard {
+                    avail_features |= 1u64 << VIRTIO_BLK_F_DISCARD;
+                }
+                if write_zeroes {
+                    avail_features |= 1u64 << VIRTIO_BLK_F_WRITE_ZEROES;
+                }
+
                 let topology = disk_image.topology();
                 info!("Disk topology: {:?}", topology);
 
@@ -771,6 +799,7 @@ impl Block {
             exit_evt,
             serial,
             queue_affinity,
+            write_zeroes_unmap,
         })
     }
 
@@ -963,6 +992,7 @@ impl VirtioDevice for Block {
                 access_platform: self.common.access_platform.clone(),
                 host_cpus: self.queue_affinity.get(&queue_idx).cloned(),
                 acked_features: self.common.acked_features,
+                write_zeroes_unmap: self.write_zeroes_unmap,
             };
 
             let paused = self.common.paused.clone();
diff --git a/vmm/src/config.rs b/vmm/src/config.rs
index 96c2e09b..df2368ee 100644
--- a/vmm/src/config.rs
+++ b/vmm/src/config.rs
@@ -1064,6 +1064,24 @@ impl RateLimiterGroupConfig {
     }
 }
 
+#[derive(Debug)]
+pub enum ParseDiscardWriteZeroesModeError {
+    InvalidValue(String),
+}
+
+impl FromStr for DiscardWriteZeroesMode {
+    type Err = ParseDiscardWriteZeroesModeError;
+
+    fn from_str(s: &str) -> result::Result<Self, Self::Err> {
+        match s.to_lowercase().as_str() {
+            "off" => Ok(DiscardWriteZeroesMode::Off),
+            "on" => Ok(DiscardWriteZeroesMode::On),
+            "unmap" => Ok(DiscardWriteZeroesMode::Unmap),
+            _ => Err(ParseDiscardWriteZeroesModeError::InvalidValue(s.to_owned())),
+        }
+    }
+}
+
 impl DiskConfig {
     pub const SYNTAX: &'static str = "Disk parameters: \
          path=<disk_image>,readonly=on|off,direct=on|off,iommu=on|off,\
@@ -1073,7 +1091,7 @@ impl DiskConfig {
          ops_size=<io_ops>,ops_one_time_burst=<io_ops>,ops_refill_time=<ms>,\
          id=<device_id>,pci_segment=<segment_id>,rate_limit_group=<group_id>,\
          queue_affinity=<list_of_queue_indices_with_their_associated_cpuset>,\
-         serial=<serial_number>";
+         serial=<serial_number>,discard=on|off,detect_zeroes=on|off|unmap";
 
     pub fn parse(disk: &str) -> Result<Self> {
         let mut parser = OptionParser::new();
@@ -1098,7 +1116,9 @@ impl DiskConfig {
             .add("pci_segment")
             .add("serial")
             .add("rate_limit_group")
-            .add("queue_affinity");
+            .add("queue_affinity")
+            .add("discard")
+            .add("detect_zeroes");
         parser.parse(disk).map_err(Error::ParseDisk)?;
 
         let path = parser.get("path").map(PathBuf::from);
@@ -1210,6 +1230,16 @@ impl DiskConfig {
             None
         };
 
+        let discard = parser
+            .convert("discard")
+            .map_err(Error::ParseDisk)?
+            .unwrap_or_default();
+
+        let detect_zeroes = parser
+            .convert("detect_zeroes")
+            .map_err(Error::ParseDisk)?
+            .unwrap_or_default();
+
         Ok(DiskConfig {
             path,
             readonly,
@@ -1227,6 +1257,8 @@ impl DiskConfig {
             pci_segment,
             serial,
             queue_affinity,
+            discard,
+            detect_zeroes,
         })
     }
 
@@ -3400,6 +3432,8 @@ mod tests {
             pci_segment: 0,
             serial: None,
             queue_affinity: None,
+            discard: DiscardWriteZeroesMode::On,
+            detect_zeroes: DiscardWriteZeroesMode::On,
         }
     }
 
diff --git a/vmm/src/device_manager.rs b/vmm/src/device_manager.rs
index 7a5adb1c..9e065216 100644
--- a/vmm/src/device_manager.rs
+++ b/vmm/src/device_manager.rs
@@ -121,8 +121,8 @@ use crate::serial_manager::{Error as SerialManagerError, SerialManager};
 use crate::vm_config::IvshmemConfig;
 use crate::vm_config::{
     ConsoleOutputMode, DEFAULT_IOMMU_ADDRESS_WIDTH_BITS, DEFAULT_PCI_SEGMENT_APERTURE_WEIGHT,
-    DeviceConfig, DiskConfig, FsConfig, NetConfig, PmemConfig, UserDeviceConfig, VdpaConfig,
-    VhostMode, VmConfig, VsockConfig,
+    DeviceConfig, DiscardWriteZeroesMode, DiskConfig, FsConfig, NetConfig, PmemConfig,
+    UserDeviceConfig, VdpaConfig, VhostMode, VmConfig, VsockConfig,
 };
 use crate::{DEVICE_MANAGER_SNAPSHOT_ID, GuestRegionMmap, PciDeviceInfo, device_node};
 
@@ -2778,6 +2778,9 @@ impl DeviceManager {
                     .clone(),
                 disk_cfg.readonly,
                 self.force_iommu | disk_cfg.iommu,
+                disk_cfg.discard != DiscardWriteZeroesMode::Off,
+                disk_cfg.detect_zeroes != DiscardWriteZeroesMode::Off,
+                disk_cfg.detect_zeroes == DiscardWriteZeroesMode::Unmap,
                 disk_cfg.num_queues,
                 disk_cfg.queue_size,
                 disk_cfg.serial.clone(),
diff --git a/vmm/src/vm_config.rs b/vmm/src/vm_config.rs
index 5828dec3..1d7d8ef9 100644
--- a/vmm/src/vm_config.rs
+++ b/vmm/src/vm_config.rs
@@ -242,6 +242,15 @@ pub struct VirtQueueAffinity {
     pub host_cpus: Vec<usize>,
 }
 
+// for discard DiscardWriteZeroesMode::On==DiscardWriteZeroesMode::Unmap
+#[derive(Clone, Debug, PartialEq, Eq, Deserialize, Serialize, Default)]
+pub enum DiscardWriteZeroesMode {
+    #[default]
+    On,
+    Off,
+    Unmap, // Special case of write zeroes
+}
+
 #[derive(Clone, Debug, PartialEq, Eq, Deserialize, Serialize)]
 pub struct DiskConfig {
     pub path: Option<PathBuf>,
@@ -276,6 +285,10 @@ pub struct DiskConfig {
     pub serial: Option<String>,
     #[serde(default)]
     pub queue_affinity: Option<Vec<VirtQueueAffinity>>,
+    #[serde(default)]
+    pub discard: DiscardWriteZeroesMode,
+    #[serde(default)]
+    pub detect_zeroes: DiscardWriteZeroesMode,
 }
 
 impl ApplyLandlock for DiskConfig {
